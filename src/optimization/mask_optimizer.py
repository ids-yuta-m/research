import os
import torch
import torch.nn as nn
import torch.optim as optim
import scipy.io as scio
import numpy as np


class MaskOptimizer:
    """ãƒã‚¹ã‚¯ã®æœ€é©åŒ–ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, network, config):
        """
        åˆæœŸåŒ–
        
        Args:
            network: æœ€é©åŒ–å¯¾è±¡ã®ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
            config: è¨­å®šè¾æ›¸
        """
        self.network = network
        self.config = config
        self.criterion = nn.MSELoss()
        self.device = next(network.parameters()).device
        
        # ä¿å­˜å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
        os.makedirs(config['io']['output_dir'], exist_ok=True)
        
        # å†æ§‹æˆéƒ¨åˆ†ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‡çµ
        self._freeze_reconstruction_layers()
    
    def _freeze_reconstruction_layers(self):
        """å†æ§‹æˆå±¤ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å‡çµã™ã‚‹"""
        for i in range(1, 10):  # unet1 ~ unet9
            getattr(self.network, f'unet{i}').requires_grad_(False)
            getattr(self.network, f'gamma{i}').requires_grad_(False)
        
        # ãƒã‚¹ã‚¯ã®ã¿æœ€é©åŒ–å¯èƒ½ã«è¨­å®š
        self.network.mask.requires_grad_(True)
    
    def optimize_mask_for_patch(self, patch, patch_num):
        """
        å˜ä¸€ãƒ‘ãƒƒãƒã‚°ãƒ«ãƒ¼ãƒ—ã«å¯¾ã—ã¦ãƒã‚¹ã‚¯ã‚’æœ€é©åŒ–
        
        Args:
            patch: å½¢çŠ¶[num_patches, t, h, w]ã®ãƒ‘ãƒƒãƒãƒ‡ãƒ¼ã‚¿
            patch_num: ãƒ‘ãƒƒãƒã‚°ãƒ«ãƒ¼ãƒ—ç•ªå·
            
        Returns:
            æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚¹ã‚¯
        """
        # è¨­å®šã®å–å¾—
        mask_lr = self.config['optimization']['mask_lr']
        epochs = self.config['optimization']['epochs']
        lr_decay_interval = self.config['optimization']['lr_decay_interval']
        lr_decay_rate = self.config['optimization']['lr_decay_rate']
        print_interval = self.config['optimization']['print_interval']
        save_dir = self.config['io']['output_dir']
        
        num_patches = patch.shape[0]
        patch = patch / 255 if patch.max() > 1.0 else patch
        
        # åˆæœŸPSNRã®è¨ˆç®—
        with torch.no_grad():
            psnrs = []
            for j in range(num_patches):
                single_frame = patch[j].unsqueeze(0)
                outputs = self.network(single_frame)
                psnr = 10 * torch.log10(1 / self.criterion(outputs[-1], single_frame))
                psnrs.append(psnr.item())
            mean_psnr = sum(psnrs) / len(psnrs)
        
        print(f"åˆæœŸPSNR: {mean_psnr:.4f}")
        
        # æœ€é©åŒ–ãƒ«ãƒ¼ãƒ—
        best_psnr = 0
        best_mask = self.network.mask.get_binary_mask()
        best_epoch = 0
        
        for epoch in range(epochs):
            optimizer = optim.Adam([self.network.mask.weight], lr=mask_lr)
            optimizer.zero_grad()
            
            total_loss = 0.0
            total_psnr = 0.0
            
            for i in range(num_patches):
                single_frame = patch[i].unsqueeze(0)
                outputs = self.network(single_frame)
                
                # æå¤±é–¢æ•°ï¼šè¤‡æ•°å‡ºåŠ›ã®é‡ã¿ä»˜ãå¹³å‡
                recon_loss = (
                    torch.sqrt(self.criterion(outputs[-1], single_frame)) +
                    0.5 * torch.sqrt(self.criterion(outputs[-2], single_frame)) +
                    0.5 * torch.sqrt(self.criterion(outputs[-3], single_frame))
                )
                
                loss = recon_loss
                loss.backward()
                
                total_loss += loss.item()
                psnr = 10 * torch.log10(1 / self.criterion(outputs[-1], single_frame))
                total_psnr += psnr.item()
            
            optimizer.step()
            
            avg_loss = total_loss / num_patches
            avg_psnr = total_psnr / num_patches
            
            # æœ€è‰¯çµæœã®ä¿å­˜
            if avg_psnr > best_psnr:
                best_psnr = avg_psnr
                best_mask = self.network.mask.get_binary_mask()
                best_epoch = epoch + 1
            
            # å­¦ç¿’ç‡ã®èª¿æ•´
            if (epoch + 1) % lr_decay_interval == 0 and epoch < 20000:
                mask_lr *= lr_decay_rate
            
            # çµŒéè¡¨ç¤º
            if (epoch + 1) % print_interval == 0:
                print(f"[{epoch+1}] LR: {mask_lr:.3e} | Loss: {avg_loss:.6f} | PSNR: {avg_psnr:.4f} | Best Epoch: {best_epoch}")
        
        # æœ€é©åŒ–çµæœã®ä¿å­˜
        self._save_mask(best_mask, save_dir, patch_num, patch, best_psnr)
        
        print(f"ğŸ”§ æœ€é©PSNR: {best_psnr:.4f}")
        return best_mask
    
    def _save_mask(self, mask, save_dir, patch_num, patch, best_psnr):
        """æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚¹ã‚¯ã®ä¿å­˜"""
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, f"mask{patch_num}.mat")
        
        # æ—¢å­˜ãƒã‚¹ã‚¯ã¨ã®æ¯”è¼ƒ
        if os.path.exists(save_path):
            saved_mask = scio.loadmat(save_path).get("mask")
            if saved_mask is not None:
                saved_mask_tensor = torch.from_numpy(saved_mask).float().to(self.device)
                self.network.mask.weight.data.copy_(saved_mask_tensor)
                with torch.no_grad():
                    outputs = self.network(patch[0].unsqueeze(0))
                    psnr_old = 10 * torch.log10(1 / self.criterion(outputs[-1], patch[0].unsqueeze(0)))
                if best_psnr > psnr_old.item():
                    scio.savemat(save_path, {'mask': mask.cpu().numpy()})
                    print("ä¸Šæ›¸ãä¿å­˜")
                else:
                    print("æ—¢å­˜ã®ãƒã‚¹ã‚¯ãŒè‰¯å¥½ãªãŸã‚ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—")
        else:
            scio.savemat(save_path, {'mask': mask.cpu().numpy()})
            print("ä¿å­˜å®Œäº†")